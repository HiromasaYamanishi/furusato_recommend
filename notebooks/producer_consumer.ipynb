{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process, Queue, Lock\n",
    "import os\n",
    "import time, random\n",
    "import torch\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda:1'\n",
    "        self.linear = torch.nn.Linear(3, 1)#.to(self.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x.relu()\n",
    "        \n",
    "def producer(queue, lock, values):\n",
    "    with lock:\n",
    "        print(f'Starting Producer: {os.getpid()}')\n",
    "        \n",
    "    for value in values:\n",
    "        time.sleep(random.randint(0, 10))\n",
    "        rands = torch.randint(low=0, high=value, size=(value,)).float()\n",
    "        mean = torch.mean(rands)\n",
    "        sm = torch.sum(rands)\n",
    "        queue.put(torch.tensor([value, mean, sm]))\n",
    "    with lock:\n",
    "        print(f'Producer {os.getpid()}, exiting')\n",
    "        \n",
    "def consumer(queue, lock, model):\n",
    "    with lock:\n",
    "        print(f'Starting Consumer {os.getpid()}')\n",
    "    while True:\n",
    "        #time.sleep(random.randint(0, 10))\n",
    "        x = queue.get()\n",
    "        x = x.to('cuda:1')\n",
    "        #print('x', x)\n",
    "        #x = x.to(self.device)\n",
    "        #print(f'{os.getpid()} got {str(x)}')\n",
    "        model = model.to('cuda:1')\n",
    "        out = model(x)\n",
    "        print('x', x, 'out', out)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 4, 5, 6, 7, 10, 13}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=set()\n",
    "s.update([13,5,6 ,3,4 , 0])\n",
    "s.update([2,4,6,7,10])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 7, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([5,7,5]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Process Exiting..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    if torch.multiprocessing.get_start_method() == 'fork':\n",
    "        torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    values = torch.randint(1, 100, size=(100, ))\n",
    "    queue = Queue()\n",
    "    lock = Lock()\n",
    "    model = Model()\n",
    "    producers = []\n",
    "    consumers = []\n",
    "    for i in range(4):\n",
    "        producers.append(Process(target=producer, args=(queue, lock, values[i*25:(i+1)*25])))\n",
    "    for j in range(1):\n",
    "        p = Process(target=consumer, args=(queue, lock, model))\n",
    "        p.daemon=True\n",
    "        consumers.append(p)   \n",
    "    \n",
    "    for p in producers:\n",
    "        p.start()\n",
    "    \n",
    "    for c in consumers:\n",
    "        c.start()\n",
    "        \n",
    "    for p in producers:\n",
    "        p.join()\n",
    "        \n",
    "    for c in consumers:\n",
    "        c.join()\n",
    "            \n",
    "    print('Parent Process Exiting..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "from multiprocessing import Process, Queue, Lock\n",
    " \n",
    " \n",
    "# Producer function that places data on the Queue\n",
    "def producer(queue, lock, names):\n",
    "    # Synchronize access to the console\n",
    "    with lock:\n",
    "        print('Starting producer => {}'.format(os.getpid()))\n",
    "         \n",
    "    # Place our names on the Queue\n",
    "    for name in names:\n",
    "        time.sleep(random.randint(0, 10))\n",
    "        queue.put(name)\n",
    " \n",
    "    # Synchronize access to the console\n",
    "    with lock:\n",
    "        print('Producer {} exiting...'.format(os.getpid()))\n",
    " \n",
    " \n",
    "# The consumer function takes data off of the Queue\n",
    "def consumer(queue, lock):\n",
    "    # Synchronize access to the console\n",
    "    with lock:\n",
    "        print('Starting consumer => {}'.format(os.getpid()))\n",
    "     \n",
    "    # Run indefinitely\n",
    "    while True:\n",
    "        time.sleep(random.randint(0, 10))\n",
    "         \n",
    "        # If the queue is empty, queue.get() will block until the queue has data\n",
    "        name = queue.get()\n",
    " \n",
    "        # Synchronize access to the console\n",
    "        with lock:\n",
    "            print('{} got {}'.format(os.getpid(), name))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "     \n",
    "    # Some lists with our favorite characters\n",
    "    names = [['Master Shake', 'Meatwad', 'Frylock', 'Carl'],\n",
    "             ['Early', 'Rusty', 'Sheriff', 'Granny', 'Lil'],\n",
    "             ['Rick', 'Morty', 'Jerry', 'Summer', 'Beth']]\n",
    " \n",
    "    # Create the Queue object\n",
    "    queue = Queue()\n",
    "     \n",
    "    # Create a lock object to synchronize resource access\n",
    "    lock = Lock()\n",
    " \n",
    "    producers = []\n",
    "    consumers = []\n",
    " \n",
    "    for n in names:\n",
    "        # Create our producer processes by passing the producer function and it's arguments\n",
    "        producers.append(Process(target=producer, args=(queue, lock, n)))\n",
    " \n",
    "    # Create consumer processes\n",
    "    for i in range(len(names) * 2):\n",
    "        p = Process(target=consumer, args=(queue, lock))\n",
    "         \n",
    "        # This is critical! The consumer function has an infinite loop\n",
    "        # Which means it will never exit unless we set daemon to true\n",
    "        p.daemon = True\n",
    "        consumers.append(p)\n",
    " \n",
    "    # Start the producers and consumer\n",
    "    # The Python VM will launch new independent processes for each Process object\n",
    "    for p in producers:\n",
    "        p.start()\n",
    " \n",
    "    for c in consumers:\n",
    "        c.start()\n",
    " \n",
    "    # Like threading, we have a join() method that synchronizes our program\n",
    "    for p in producers:\n",
    "        p.join()\n",
    " \n",
    "    print('Parent process exiting...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "torch.multiprocessing.set_start_method('fork', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 105, in spawn_main\n",
      "    exitcode = _main(fd)\n",
      "  File \"/home/yamanishi/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/multiprocessing/spawn.py\", line 115, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'forward_pro_con'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1551476/2424433970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pro_con\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/tr/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'forward_pro_con'"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.forward_pro_con()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 10 but got size 20 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_431573/3504988917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 10 but got size 20 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "a = [torch.rand(10,10), torch.rand(20, 10), torch.rand(40,10)]\n",
    "torch.cat(a, dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1462950125206013, 0),\n",
       " (0.9821005152771285, 5),\n",
       " (0.3021859665836796, 4),\n",
       " (0.10078272162970381, 5),\n",
       " (0.33966428175769503, 2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "num_calc=100\n",
    "num_tasks=5\n",
    "A=[0,5,4,5,2]\n",
    "list(map(lambda _: (random.random(), A[_]), range(num_tasks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "data = Planetoid('./', name='Cora')[0]\n",
    "\n",
    "loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    "    input_nodes=data.train_mask,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(loader))\n",
    "print(sampled_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1104421/1104421 [00:10<00:00, 108886.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "train_file = '../data/cf/train.txt'\n",
    "trainUniqueUsers, trainUser, trainItem, allPos = [], [], [], []\n",
    "traindataSize, m_item, n_user = 0, 0, 0\n",
    "with open(train_file) as f:\n",
    "    for l in tqdm(f.readlines()):\n",
    "        if len(l) > 0:\n",
    "            l = l.strip('\\n').split(' ')\n",
    "            items = [int(i) for i in l[1:]]\n",
    "            uid = int(l[0])\n",
    "            trainUniqueUsers.append(uid)\n",
    "            trainUser.extend([uid] * len(items))\n",
    "            trainItem.extend(items)\n",
    "            allPos.append(np.array(items))\n",
    "            m_item = max(m_item, max(items))\n",
    "            n_user = max(n_user, uid)\n",
    "            traindataSize += len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index=torch.cat([torch.stack([torch.tensor(trainUser), torch.tensor(trainItem)+n_user], dim=0), torch.stack([torch.tensor(trainItem)+n_user, torch.tensor(trainUser)], dim=0)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = torch.randint(0, n_user, size=(20000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "train_loader = NeighborSampler(edge_index, node_idx=user,\n",
    "                               sizes=[10, 10], batch_size=2048,\n",
    "                               shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "train_loader = NeighborSampler(edge_index, node_idx=None,\n",
    "                               sizes=[-1], batch_size=2048,\n",
    "                               shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 tensor([   0,    1,    2,  ..., 8383, 8384, 8385]) EdgeIndex(edge_index=tensor([[1568, 1569, 1570,  ..., 7281, 7891, 8385],\n",
      "        [   0,    0,    0,  ..., 1567, 1567, 1567]]), e_id=tensor([    0,     1,     2,  ..., 14337, 14338, 14339]), size=(8386, 2048)) tensor([[1568, 1569, 1570,  ..., 7281, 7891, 8385],\n",
      "        [   0,    0,    0,  ..., 1567, 1567, 1567]]) (8386, 2048)\n",
      "2048 tensor([2048, 2049, 2050,  ..., 4093, 4094, 4095]) EdgeIndex(edge_index=tensor([], size=(2, 0), dtype=torch.int64), e_id=tensor([], dtype=torch.int64), size=(2048, 2048)) tensor([], size=(2, 0), dtype=torch.int64) (2048, 2048)\n",
      "2048 tensor([4096, 4097, 4098,  ..., 6141, 6142, 6143]) EdgeIndex(edge_index=tensor([], size=(2, 0), dtype=torch.int64), e_id=tensor([], dtype=torch.int64), size=(2048, 2048)) tensor([], size=(2, 0), dtype=torch.int64) (2048, 2048)\n",
      "2048 tensor([6144, 6145, 6146,  ..., 8189, 8190, 8191]) EdgeIndex(edge_index=tensor([], size=(2, 0), dtype=torch.int64), e_id=tensor([], dtype=torch.int64), size=(2048, 2048)) tensor([], size=(2, 0), dtype=torch.int64) (2048, 2048)\n",
      "194 tensor([8192, 8193, 8194, 8195, 8196, 8197, 8198, 8199, 8200, 8201, 8202, 8203,\n",
      "        8204, 8205, 8206, 8207, 8208, 8209, 8210, 8211, 8212, 8213, 8214, 8215,\n",
      "        8216, 8217, 8218, 8219, 8220, 8221, 8222, 8223, 8224, 8225, 8226, 8227,\n",
      "        8228, 8229, 8230, 8231, 8232, 8233, 8234, 8235, 8236, 8237, 8238, 8239,\n",
      "        8240, 8241, 8242, 8243, 8244, 8245, 8246, 8247, 8248, 8249, 8250, 8251,\n",
      "        8252, 8253, 8254, 8255, 8256, 8257, 8258, 8259, 8260, 8261, 8262, 8263,\n",
      "        8264, 8265, 8266, 8267, 8268, 8269, 8270, 8271, 8272, 8273, 8274, 8275,\n",
      "        8276, 8277, 8278, 8279, 8280, 8281, 8282, 8283, 8284, 8285, 8286, 8287,\n",
      "        8288, 8289, 8290, 8291, 8292, 8293, 8294, 8295, 8296, 8297, 8298, 8299,\n",
      "        8300, 8301, 8302, 8303, 8304, 8305, 8306, 8307, 8308, 8309, 8310, 8311,\n",
      "        8312, 8313, 8314, 8315, 8316, 8317, 8318, 8319, 8320, 8321, 8322, 8323,\n",
      "        8324, 8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334, 8335,\n",
      "        8336, 8337, 8338, 8339, 8340, 8341, 8342, 8343, 8344, 8345, 8346, 8347,\n",
      "        8348, 8349, 8350, 8351, 8352, 8353, 8354, 8355, 8356, 8357, 8358, 8359,\n",
      "        8360, 8361, 8362, 8363, 8364, 8365, 8366, 8367, 8368, 8369, 8370, 8371,\n",
      "        8372, 8373, 8374, 8375, 8376, 8377, 8378, 8379, 8380, 8381, 8382, 8383,\n",
      "        8384, 8385]) EdgeIndex(edge_index=tensor([], size=(2, 0), dtype=torch.int64), e_id=tensor([], dtype=torch.int64), size=(194, 194)) tensor([], size=(2, 0), dtype=torch.int64) (194, 194)\n"
     ]
    }
   ],
   "source": [
    "for batch_size, n_id, adj in train_loader:\n",
    "    edge_index, _, size = adj\n",
    "    print(batch_size, n_id, adj, edge_index,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.zeros((5, 10))], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.randint(n_user, n_user+m_item-1, size=(10000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "train_loader = NeighborSampler(edge_index, node_idx=pos,\n",
    "                               sizes=[10, 10], batch_size=512,\n",
    "                               shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NegativeSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([486302, 564387, 614087,  ..., 247308, 118692, 778755])\n",
      "n_id tensor([   0,    1,    2,  ..., 8383, 8384, 8385])\n",
      "n_id size torch.Size([8386])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1551476/3658108203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(n_id[:batch_size])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_id size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0madjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0madj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1551476/3658108203.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(n_id[:batch_size])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_id size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0madjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0madj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "node_idx = user\n",
    "print(node_idx)\n",
    "for batch_size, n_id, adjs in train_loader:\n",
    "    # `adjs` holds a list of `(edge_index, e_id, size)` tuples.\n",
    "    print('n_id',n_id)\n",
    "    #for nn in n_id:\n",
    "    #    print(nn)\n",
    "    #print(pos)\n",
    "    #print(n_id[:batch_size])\n",
    "    print('n_id size', n_id.size())\n",
    "    adjs = [adj.to(device) for adj in adjs]\n",
    "    for i,(edge_index, _, size) in enumerate(adjs):\n",
    "        print(edge_index)\n",
    "        #for v in edge_index[1].unique():\n",
    "        #    print(edge_index[:,edge_index[1]==v].size(1))\n",
    "        print('edge index shape', edge_index.shape)\n",
    "        #print(_)\n",
    "        #print(_.size())\n",
    "        print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000%512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set({1,2,3,4,5})\n",
    "a.update(set([3,5,6,7]))\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study_group",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a865c41608e708ace9ed6e40a66ff8f45d4fe73a2fce76e3bb9141e87d20f44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
